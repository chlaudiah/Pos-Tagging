{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> POS-Tagging dengan Metode Statistika </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> A. Pembangunan Model Data Train </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(fname):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    idx_line = 0\n",
    "    while idx_line < len(content):\n",
    "        sent = [] #untuk menampung katanya\n",
    "        tag = [] #untuk menampung postag dari tiap kata\n",
    "#         print('idx_line =')\n",
    "#         print(idx_line)\n",
    "        while not content[idx_line].startswith('</kalimat'): #batas akhir dari kalimat\n",
    "            if  not content[idx_line].startswith('<kalimat'):\n",
    "                content_part = content[idx_line].split('\\t')\n",
    "                sent.append(content_part[0])\n",
    "                tag.append(content_part[1])\n",
    "            idx_line = idx_line + 1\n",
    "        sentences.append(sent)\n",
    "        tags.append(tag)\n",
    "        idx_line = idx_line+2        \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index): #feature yang digunakan adalah awalan dan akhiran,informasi context, bentuk karakter, dan jenis kata\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    \n",
    "    \n",
    "    #Kamus diambil dari Kamus yang didefinisikan pada website http://bahasa.cs.ui.ac.id/postag/corpus (nama file: '1-1 tag dict.txt')\n",
    "    tanda_baca = ['\"','`','!','.','?',';','(',')','[',']','{','}',',','&']\n",
    "    simbol_matematika = ['$','%','*','/',':','+','-','=','<','>']\n",
    "    kata_angka = ['satu','dua','tiga','empat','lima','enam','tujuh','delapan','sembilan','puluh','belas','ratus','ribu','juta','miliar','triliun','seantero','beberapa','semua','seluruh','ke','seper','nya']\n",
    "    modal = ['harus','mungkin','pernah','sudah','telah']\n",
    "    negatif = ['belum','bukan','jangan','kagak','nggak','tak','tidak']\n",
    "    kata_hubung = ['apalagi','atau','ataupun','dan','jangankan','kemudian','lalu','namun','padahal','sedangkan','tetapi']\n",
    "    determiner = ['para','sang','si','sebuah']\n",
    "    posisi = ['kepada','oleh','dalam','terhadap',]\n",
    "    subjek_rujukan = ['beliau','dia','dikau','engkau','ia','kalian','kami','kamu','kau','kita','mereka','saya','seseorang','sesuatu']\n",
    "    keterangan = ['apabila','asalkan','bahwa','yaitu','yakni','untuk','pun','yang']\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "                                                            #Feature tempat kata\n",
    "        'kata_pertama': index == 0,\n",
    "        'kata_terakhir': index == len(sentence)-1,\n",
    "        \n",
    "                                                                      #Feature Bentuk Karakter dan Jenis kata\n",
    "        'nama_entitas':sentence[index][0].upper() == sentence[index][0],\n",
    "        'simbol': sentence[index].upper() == sentence[index][:2] or 'Rp' in sentence[index],\n",
    "        'angka': sentence[index].isdigit() == sentence[index],\n",
    "        'subjek': sentence[index].lower() == sentence[index] and ((sentence[index] not in tanda_baca) \n",
    "                                                                  or (sentence[index] not in simbol_matematika) or (sentence[index] not in kata_angka) \n",
    "                                                                  or (sentence[index] not in kata_angka) or (sentence[index] not in modal)\n",
    "                                                                  or (sentence[index] not in negatif) or (sentence[index] not in kata_hubung)\n",
    "                                                                  or (sentence[index] not in determiner) or (sentence[index] not in posisi)\n",
    "                                                                  or (sentence[index] not in subjek_rujukan) or (sentence[index] not in keterangan)),\n",
    "        'kata_angka': (sentence[index] in kata_angka) or (sentence[index][:2] in kata_angka) or (sentence[index][-3:] in kata_angka) \n",
    "                            or (sentence[index][:5] in kata_angka) or ((sentence[index][:2] in kata_angka) and (sentence[index][-3:] in kata_angka)) or ('pertama' in sentence[index]) ,\n",
    "        'tanda-baca': sentence[index] in tanda_baca,\n",
    "        'simbol_mtk': sentence[index] in simbol_matematika,\n",
    "        'modal': sentence[index] in modal,\n",
    "        'sambung': '-' in sentence[index],\n",
    "        'kata-hubung': sentence[index] in kata_hubung,\n",
    "        'determiner': sentence[index] in determiner,\n",
    "        'posisi': sentence[index] in posisi,\n",
    "        'rujukan': sentence[index] in subjek_rujukan,\n",
    "        'keterangan': sentence[index] in keterangan or sentence[index][-3:] in keterangan,\n",
    "        \n",
    "        #awalan dan akhiran dari kata\n",
    "        'prefix-1': sentence[index][0], #prefix adalah karakter awal dari kata\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:], #suffix adalah karakter akhir dari kata\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        \n",
    "        #informasi context\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dataset(sentences, tags): #ekstraksi feature\n",
    "    X, y = [], []\n",
    "    for sentence_idx in range(len(sentences)):\n",
    "        for index in range(len(sentences[sentence_idx])):\n",
    "            X.append(features(sentences[sentence_idx], index))\n",
    "            y.append(tags[sentence_idx][index])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, tags = read_dataset('Data_Train.txt') #membaca data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(.70 * len(sentences))\n",
    "\n",
    "#Memisahkan data train dengan data validasi (train: 70% dan validasi: 30%)\n",
    "training_sentences = sentences[cutoff:] #data train\n",
    "training_tags = tags[cutoff:]\n",
    "\n",
    "test_sentences = sentences[:cutoff] #data validasi\n",
    "test_tags = tags[:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data training ke-0 =\n",
      "{'word': 'Dana', 'kata_pertama': True, 'kata_terakhir': False, 'nama_entitas': True, 'simbol': False, 'angka': False, 'subjek': False, 'kata_angka': False, 'tanda-baca': False, 'simbol_mtk': False, 'modal': False, 'sambung': False, 'kata-hubung': False, 'determiner': False, 'posisi': False, 'rujukan': False, 'keterangan': False, 'prefix-1': 'D', 'prefix-2': 'Da', 'prefix-3': 'Dan', 'suffix-1': 'a', 'suffix-2': 'na', 'suffix-3': 'ana', 'prev_word': '', 'next_word': 'pinjaman'}\n",
      "label training ke-0 =\n",
      "NN\n"
     ]
    }
   ],
   "source": [
    "X, y = transform_to_dataset(training_sentences, training_tags) #Melakukan ekstrasi feature terhadap data train\n",
    "print('data training ke-0 =')\n",
    "print(X[0])\n",
    "print('label training ke-0 =')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan klasifikasi dengan menggunakan naive bayes \n",
    "clf = Pipeline([\n",
    "        ('vectorizer', DictVectorizer(sparse=False)),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "clf.fit(X[:1030], y[:1030])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.7956760877852203\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = transform_to_dataset(test_sentences, test_tags) #Ekstraksi feature terhadap data validasi\n",
    "print(\"Accuracy:\")\n",
    "print(clf.score(X_test, y_test)) #Menghitung score yang diperoleh setelah proses klasifikasi pada data validasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> B. Pengujian Model Data Train </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NN', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'CD', 'NN', 'OD', 'SC', 'VB', 'NNP', 'CD', 'VB', 'VB', 'NN', 'SYM', 'CD', 'CD', 'Z', 'CC', 'VB', 'CD', 'CD', 'IN', 'SYM', 'CD', 'CD', 'IN', 'NN', 'JJ', 'NN', 'CC', 'Z', 'NN', 'JJ', 'NN', 'VB', 'VB', 'IN', 'SYM', 'CD', 'CD', 'IN', 'NN', 'OD', 'CD', 'VB', 'SYM', 'CD', 'CD', 'IN', 'NN', 'OD', 'CD', 'Z', 'CC', 'NN', 'NN', 'IN', 'NN', 'PR', 'VB', 'IN', 'NN', 'SYM', 'CD', 'CD', 'VB', 'SYM', 'CD', 'CD', 'Z', 'IN', 'NN', 'JJ', 'Z', 'NN', 'NN', 'VB', 'VB', 'NN', 'JJ', 'JJ', 'NN', 'IN', 'SYM', 'CD', 'CD', 'IN', 'NN', 'OD', 'NN', 'CC', 'VB', 'SYM', 'CD', 'CD', 'IN', 'NN', 'OD', 'NN', 'PR', 'Z', 'SC', 'NN', 'PRP', 'MD', 'RB', 'VB', 'Z', 'IN', 'NN', 'CD', 'NNP', 'VB', 'VB', 'NN', 'JJ', 'SYM', 'CD', 'CD', 'Z', 'CD', 'CD', 'X', 'MD', 'VB', 'IN', 'NN', 'SC', 'NN', 'NN', 'CD', 'Z', 'SC', 'JJ', 'SYM', 'CD', 'CD', 'CC', 'SYM', 'CD', 'IN', 'NND', 'NN', 'Z', 'NN', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NN', 'OD', 'CD', 'VB', 'VB', 'NN', 'SYM', 'CD', 'CD', 'Z', 'VB', 'IN', 'CD', 'CD', 'IN', 'NN', 'JJ', 'NN', 'CC', 'SYM', 'CD', 'CD', 'Z', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'Z', 'IN', 'NN', 'NN', 'NNP', 'Z', 'VB', 'VB', 'PRP', 'NN', 'PR', 'VB', 'VB', 'PRP', 'NN', 'JJ', 'NN', 'SC', 'VB', 'CD', 'CD', 'VB', 'SYM', 'CD', 'CD', 'IN', 'CD', 'NN', 'OD', 'CD', 'VB', 'NN', 'JJ', 'CD', 'SYM', 'CD', 'CD', 'Z', 'CC', 'NN', 'NN', 'RB', 'VB', 'CD', 'CD', 'VB', 'IN', 'CD', 'CD', 'NN', 'OD', 'CD', 'VB', 'SYM', 'CD', 'CD', 'IN', 'NN', 'OD', 'CD', 'Z', 'IN', 'NNP', 'Z', 'VB', 'PRP', 'NN', 'PR', 'SC', 'NN', 'VB', 'VB', 'NN', 'NN', 'JJ', 'CD', 'CD', 'VB', 'CD', 'CD', 'NN', 'IN', 'NN', 'OD', 'CD', 'VB', 'NN', 'JJ', 'CD', 'CD', 'CD', 'CD', 'NN', 'Z', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'VB', 'NNP', 'NNP', 'NNP', 'VB', 'NN', 'SC', 'NN', 'PR', 'JJ', 'IN', 'NN', 'SYM', 'CD', 'IN', 'NN', 'NNP', 'SC', 'NN', 'JJ', 'NEG', 'VB', 'Z', 'PRP', 'MD', 'VB', 'RB', 'JJ', 'IN', 'NN', 'NN', 'PRP', 'PRP', 'VB', 'Z', 'SC', 'PRP', 'VB', 'RB', 'RB', 'IN', 'Z', 'FW', 'Z', 'SC', 'RB', 'VB', 'Z', 'VB', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'Z', 'NNP', 'Z', 'PRP', 'VB', 'NN', 'NN', 'NN', 'PR', 'VB', 'SC', 'NEG', 'VB', 'NN', 'SC', 'VB', 'IN', 'NN', 'Z', 'NEG', 'SC', 'VB', 'NN', 'IN', 'NN', 'SC', 'RB', 'JJ', 'NN', 'NN', 'SC', 'PR', 'MD', 'VB', 'NN', 'Z', 'VB', 'NNP', 'Z', 'NNP', 'RB', 'VB', 'SC', 'NNP', 'NEG', 'VB', 'NN', 'SC', 'VB', 'NN', 'IN', 'Z', 'FW', 'Z', 'Z', 'DT', 'VB', 'PR', 'NN', 'PRP', 'Z', 'NEG', 'Z', 'FW', 'PRP', 'Z', 'PRP', 'NEG', 'VB', 'Z', 'FW', 'Z', 'WH', 'Z', 'VB', 'NNP', 'Z', 'SC', 'PR', 'SC', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'VB', 'NN', 'NN', 'Z', 'SC', 'VB', 'IN', 'CD', 'NN', 'NN', 'JJ', 'VB', 'NN', 'Z', 'SC', 'OD', 'SYM', 'CD', 'CD', 'CC', 'SC', 'OD', 'VB', 'NN', 'WH', 'CD', 'Z', 'FW', 'PRP', 'SC', 'NEG', 'FW', 'FW', 'Z', 'VB', 'FW', 'PRP', 'Z', 'VB', 'NNP', 'Z', 'NN', 'PR', 'IN', 'NNP', 'VB', 'NN', 'SC', 'JJ', 'WH', 'NN', 'NN', 'IN', 'NN', 'VB', 'VB', 'Z', 'NN', 'IN', 'NN', 'NN', 'MD', 'VB', 'VB', 'Z', 'RB', 'NN', 'PRP', 'NEG', 'IN', 'PRP', 'VB', 'Z']\n"
     ]
    }
   ],
   "source": [
    "sentences_test, tag_test = read_dataset('Data_Test.txt')\n",
    "kumpulan_tag = []\n",
    "kumpulan_kata = []\n",
    "\n",
    "for tag in tag_test:\n",
    "    for i in range(len(tag)):\n",
    "        kumpulan_tag.append(tag[i]) #mengambil tag dalam datatest\n",
    "        \n",
    "for sentence in sentences_test:\n",
    "    for i in range(len(sentence)):\n",
    "        kumpulan_kata.append(sentence[i]) #mengambil kata dalam datatest\n",
    "print(kumpulan_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_tag = [] #menampung hasil prediksi tag dari hasil klasifikasi \n",
    "for sentence in sentences_test:\n",
    "    pos_tag = clf.predict([features(sentence, index) for index in range(len(sentence))]) #ekstraksi feature dan klasifikasi data test\n",
    "    for tag in pos_tag:\n",
    "        hasil_tag.append(tag) #memasukkan seluruh tag hasil prediksi kedalam array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "2. Kata: lalu Tag Test: JJ Tag Asli: CC\n",
      "3. Kata: bersih Tag Test: VB Tag Asli: JJ\n",
      "4. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "5. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "6. Kata: namun Tag Test: NN Tag Asli: CC\n",
      "7. Kata: beban Tag Test: VB Tag Asli: NN\n",
      "8. Kata: bersih Tag Test: VB Tag Asli: JJ\n",
      "9. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "10. Kata: lalu Tag Test: JJ Tag Asli: CC\n",
      "11. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "12. Kata: sehingga Tag Test: NN Tag Asli: SC\n",
      "13. Kata: tetap Tag Test: VB Tag Asli: RB\n",
      "14. Kata: diantaranya Tag Test: PRP Tag Asli: X\n",
      "15. Kata: untuk Tag Test: IN Tag Asli: SC\n",
      "16. Kata: per Tag Test: NN Tag Asli: IN\n",
      "17. Kata: lembar Tag Test: NN Tag Asli: NND\n",
      "18. Kata: - Tag Test: Z Tag Asli: NNP\n",
      "19. Kata: 8 Tag Test: CD Tag Asli: NNP\n",
      "20. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "21. Kata: sekitar Tag Test: JJ Tag Asli: IN\n",
      "22. Kata: lalu Tag Test: JJ Tag Asli: CC\n",
      "23. Kata: kotor Tag Test: NN Tag Asli: JJ\n",
      "24. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "25. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "26. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "27. Kata: karena Tag Test: IN Tag Asli: SC\n",
      "28. Kata: hingga Tag Test: NN Tag Asli: IN\n",
      "29. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "30. Kata: sebanyak Tag Test: NN Tag Asli: CD\n",
      "31. Kata: satu Tag Test: NN Tag Asli: CD\n",
      "32. Kata: stabil Tag Test: NN Tag Asli: JJ\n",
      "33. Kata: per Tag Test: NN Tag Asli: IN\n",
      "34. Kata: agar Tag Test: NN Tag Asli: SC\n",
      "35. Kata: riil Tag Test: NN Tag Asli: JJ\n",
      "36. Kata: tidak Tag Test: NN Tag Asli: NEG\n",
      "37. Kata: terganggu Tag Test: JJ Tag Asli: VB\n",
      "38. Kata: Kita Tag Test: NNP Tag Asli: PRP\n",
      "39. Kata: tetap Tag Test: VB Tag Asli: RB\n",
      "40. Kata: stabil Tag Test: NN Tag Asli: JJ\n",
      "41. Kata: kita Tag Test: NN Tag Asli: PRP\n",
      "42. Kata: jaga Tag Test: NN Tag Asli: VB\n",
      "43. Kata: kalaupun Tag Test: VB Tag Asli: SC\n",
      "44. Kata: ia Tag Test: NN Tag Asli: PRP\n",
      "45. Kata: tentu Tag Test: NN Tag Asli: RB\n",
      "46. Kata: saja Tag Test: NN Tag Asli: RB\n",
      "47. Kata: volatility Tag Test: NN Tag Asli: FW\n",
      "48. Kata: sangat Tag Test: NN Tag Asli: RB\n",
      "49. Kata: terukur Tag Test: NN Tag Asli: VB\n",
      "50. Kata: Ia Tag Test: NNP Tag Asli: PRP\n",
      "51. Kata: agar Tag Test: NN Tag Asli: SC\n",
      "52. Kata: tidak Tag Test: NN Tag Asli: NEG\n",
      "53. Kata: Jangan Tag Test: NNP Tag Asli: NEG\n",
      "54. Kata: sampai Tag Test: IN Tag Asli: SC\n",
      "55. Kata: sangat Tag Test: NN Tag Asli: RB\n",
      "56. Kata: dekat Tag Test: NN Tag Asli: JJ\n",
      "57. Kata: karena Tag Test: IN Tag Asli: SC\n",
      "58. Kata: tidak Tag Test: NN Tag Asli: NEG\n",
      "59. Kata: melalui Tag Test: VB Tag Asli: IN\n",
      "60. Kata: Yang Tag Test: NNP Tag Asli: DT\n",
      "61. Kata: bukan Tag Test: NN Tag Asli: NEG\n",
      "62. Kata: kita Tag Test: NN Tag Asli: PRP\n",
      "63. Kata: tidak Tag Test: NN Tag Asli: NEG\n",
      "64. Kata: berapa Tag Test: VB Tag Asli: WH\n",
      "65. Kata: Sementara Tag Test: NNP Tag Asli: SC\n",
      "66. Kata: menurut Tag Test: VB Tag Asli: IN\n",
      "67. Kata: Kalau Tag Test: NNP Tag Asli: SC\n",
      "68. Kata: dua Tag Test: NN Tag Asli: CD\n",
      "69. Kata: kali Tag Test: VB Tag Asli: NN\n",
      "70. Kata: lelang Tag Test: SC Tag Asli: NN\n",
      "71. Kata: pertama Tag Test: NN Tag Asli: OD\n",
      "72. Kata: kedua Tag Test: NN Tag Asli: OD\n",
      "73. Kata: berapa Tag Test: VB Tag Asli: WH\n",
      "74. Kata: trend Tag Test: NN Tag Asli: FW\n",
      "75. Kata: kalau Tag Test: NN Tag Asli: SC\n",
      "76. Kata: tidak Tag Test: NN Tag Asli: NEG\n",
      "77. Kata: levelling Tag Test: SC Tag Asli: FW\n",
      "78. Kata: off Tag Test: NN Tag Asli: FW\n",
      "79. Kata: trend Tag Test: NN Tag Asli: FW\n",
      "80. Kata: Hal Tag Test: NNP Tag Asli: NN\n",
      "81. Kata: menurut Tag Test: VB Tag Asli: IN\n",
      "82. Kata: baik Tag Test: VB Tag Asli: JJ\n",
      "83. Kata: di mana Tag Test: NN Tag Asli: WH\n",
      "84. Kata: bergulir Tag Test: JJ Tag Asli: VB\n",
      "85. Kata: bidang Tag Test: SC Tag Asli: NN\n",
      "86. Kata: sudah Tag Test: NN Tag Asli: MD\n",
      "87. Kata: memang Tag Test: VB Tag Asli: RB\n",
      "88. Kata: belum Tag Test: NN Tag Asli: NEG\n",
      "89. Kata: seperti Tag Test: NN Tag Asli: IN\n",
      "90. Kata: kita Tag Test: NN Tag Asli: PRP\n",
      "91. Kata: inginkan Tag Test: NN Tag Asli: VB\n",
      "91\n",
      "81.76352705410822\n"
     ]
    }
   ],
   "source": [
    "                                   #Perhitungan akurasi\n",
    "jumlah_tag = 0\n",
    "jumlah_salah = 0\n",
    "akurasi = 0\n",
    "for i in range(len(kumpulan_tag)):\n",
    "    if hasil_tag[i] == kumpulan_tag[i]:\n",
    "        jumlah_tag += 1\n",
    "    else:\n",
    "        jumlah_salah += 1\n",
    "        print(str(jumlah_salah)+'.', 'Kata: '+ kumpulan_kata[i], 'Tag Test: '+hasil_tag[i], 'Tag Asli: '+kumpulan_tag[i])\n",
    "#         print('---------------------')\n",
    "print(jumlah_salah)\n",
    "akurasi = (jumlah_tag/len(kumpulan_tag)) * 100\n",
    "print(akurasi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
